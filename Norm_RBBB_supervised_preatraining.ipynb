{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 16:07:54.557159: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 16:07:55.085099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-09 16:07:55.085159: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-09 16:07:55.085165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "import models.resnet as resnet\n",
    "\n",
    "import sys\n",
    "\n",
    "import data_augmentation as da\n",
    "import data_visualisation as dv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "X_folds\n",
      "Y\n",
      "Y_text\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "thismodule = sys.modules[__name__]\n",
    "\n",
    "with np.load('data/DAT_China_pretrain_1s_HB.npz', allow_pickle=True) as data:\n",
    "    for k in data.keys():\n",
    "        print(k)\n",
    "        if 'text' in k:\n",
    "            setattr(thismodule, k, data[k])\n",
    "        else:\n",
    "            setattr(thismodule, k, data[k].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (282615, 100, 12)\n",
      "X_folds (282615,)\n",
      "Y (282615,)\n",
      "Y_text (282615,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X\", X.shape)\n",
    "print(\"X_folds\", X_folds.shape)\n",
    "print(\"Y\", Y.shape)\n",
    "print(\"Y_text\", Y_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (247380, 100, 12)\n",
      "Y_train (247380,)\n",
      "X_test (35235, 100, 12)\n",
      "Y_test (35235,)\n"
     ]
    }
   ],
   "source": [
    "# take fold 7 as test set\n",
    "X_train = X[X_folds != 7]\n",
    "Y_train = Y[X_folds != 7]\n",
    "X_test = X[X_folds == 7]\n",
    "Y_test = Y[X_folds == 7]\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"Y_train\", Y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"Y_test\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_ecg_signal(signal):\n",
    "    drifted_signal, _ = da.add_random_baseline_drift(signal, strength_range=(1.5,2.5), drift_wavelength_range=(300,500))\n",
    "    noised_drifted_signal = da.add_random_noise(drifted_signal, (0, 0.2))\n",
    "    return noised_drifted_signal\n",
    "\n",
    "def augment_ecg_signal_batch(signals, labels, batch_size):\n",
    "    while True:\n",
    "        \n",
    "        indices = np.random.randint(0, signals.shape[0], size=batch_size)\n",
    "        batch = signals[indices]\n",
    "        batch_labels = labels[indices]\n",
    "        \n",
    "        augmented_batch = np.array([augment_ecg_signal(sample) for sample in batch])\n",
    "        \n",
    "        yield (augmented_batch, batch_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 16:00:36.413615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:00:36.471776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:00:36.471973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:00:36.472427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 16:00:36.473212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:00:36.473376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:00:36.473524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:00:36.929591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:00:36.929791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:00:36.929945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:00:36.930079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5601 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 12)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 96, 16)       976         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, 96, 16)       64          ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 96, 16)       0           ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 48, 16)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv_1_1 (Conv1D)              (None, 48, 16)       1296        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " bn_1_1 (BatchNormalization)    (None, 48, 16)       64          ['conv_1_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 48, 16)       0           ['bn_1_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_1_2 (Conv1D)              (None, 48, 16)       784         ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " bn_1_2 (BatchNormalization)    (None, 48, 16)       64          ['conv_1_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 48, 32)       0           ['bn_1_2[0][0]',                 \n",
      "                                                                  'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 48, 32)       0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv_2_1 (Conv1D)              (None, 48, 16)       2576        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " bn_2_1 (BatchNormalization)    (None, 48, 16)       64          ['conv_2_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 48, 16)       0           ['bn_2_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_2_2 (Conv1D)              (None, 48, 16)       784         ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " bn_2_2 (BatchNormalization)    (None, 48, 16)       64          ['conv_2_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 48, 48)       0           ['bn_2_2[0][0]',                 \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 48, 48)       0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 24, 48)      0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv_3_1 (Conv1D)              (None, 24, 16)       3856        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " bn_3_1 (BatchNormalization)    (None, 24, 16)       64          ['conv_3_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 24, 16)       0           ['bn_3_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_3_2 (Conv1D)              (None, 24, 16)       784         ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " bn_3_2 (BatchNormalization)    (None, 24, 16)       64          ['conv_3_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 24, 64)       0           ['bn_3_2[0][0]',                 \n",
      "                                                                  'max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 24, 64)       0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv_4_1 (Conv1D)              (None, 24, 16)       5136        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " bn_4_1 (BatchNormalization)    (None, 24, 16)       64          ['conv_4_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 24, 16)       0           ['bn_4_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_4_2 (Conv1D)              (None, 24, 16)       784         ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " bn_4_2 (BatchNormalization)    (None, 24, 16)       64          ['conv_4_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 24, 80)       0           ['bn_4_2[0][0]',                 \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 24, 80)       0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv_5_1 (Conv1D)              (None, 24, 16)       6416        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " bn_5_1 (BatchNormalization)    (None, 24, 16)       64          ['conv_5_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 24, 16)       0           ['bn_5_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_5_2 (Conv1D)              (None, 24, 16)       784         ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " bn_5_2 (BatchNormalization)    (None, 24, 16)       64          ['conv_5_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 24, 96)       0           ['bn_5_2[0][0]',                 \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 24, 96)       0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv_6_1 (Conv1D)              (None, 24, 16)       7696        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " bn_6_1 (BatchNormalization)    (None, 24, 16)       64          ['conv_6_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 24, 16)       0           ['bn_6_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_6_2 (Conv1D)              (None, 24, 16)       784         ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " bn_6_2 (BatchNormalization)    (None, 24, 16)       64          ['conv_6_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 24, 112)      0           ['bn_6_2[0][0]',                 \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 24, 112)      0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv_7_1 (Conv1D)              (None, 24, 16)       8976        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " bn_7_1 (BatchNormalization)    (None, 24, 16)       64          ['conv_7_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 24, 16)       0           ['bn_7_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_7_2 (Conv1D)              (None, 24, 16)       784         ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " bn_7_2 (BatchNormalization)    (None, 24, 16)       64          ['conv_7_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 24, 128)      0           ['bn_7_2[0][0]',                 \n",
      "                                                                  'activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 24, 128)      0           ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " conv_8_1 (Conv1D)              (None, 24, 16)       10256       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " bn_8_1 (BatchNormalization)    (None, 24, 16)       64          ['conv_8_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 24, 16)       0           ['bn_8_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_8_2 (Conv1D)              (None, 24, 16)       784         ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " bn_8_2 (BatchNormalization)    (None, 24, 16)       64          ['conv_8_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 24, 144)      0           ['bn_8_2[0][0]',                 \n",
      "                                                                  'activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 24, 144)      0           ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv_9_1 (Conv1D)              (None, 24, 16)       11536       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " bn_9_1 (BatchNormalization)    (None, 24, 16)       64          ['conv_9_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 24, 16)       0           ['bn_9_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_9_2 (Conv1D)              (None, 24, 16)       784         ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " bn_9_2 (BatchNormalization)    (None, 24, 16)       64          ['conv_9_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 24, 160)      0           ['bn_9_2[0][0]',                 \n",
      "                                                                  'activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 24, 160)      0           ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv_10_1 (Conv1D)             (None, 24, 16)       12816       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " bn_10_1 (BatchNormalization)   (None, 24, 16)       64          ['conv_10_1[0][0]']              \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 24, 16)       0           ['bn_10_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv_10_2 (Conv1D)             (None, 24, 16)       784         ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " bn_10_2 (BatchNormalization)   (None, 24, 16)       64          ['conv_10_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 24, 176)      0           ['bn_10_2[0][0]',                \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 24, 176)      0           ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 176)         0           ['activation_20[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 176)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 128)          22656       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 64)           8256        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            65          ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 111,697\n",
      "Trainable params: 111,025\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 1\n",
    "X_input = keras.Input(shape=X.shape[1:])\n",
    "\n",
    "out, _ = resnet.model(X_input, num_classes=num_classes, filters = [16, 16], kernels = [5, 3], layers=10, hidden_units=128)\n",
    "model = keras.Model(inputs=X_input, outputs=out)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall', metrics.binary_accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 16:00:44.401623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8907\n",
      "2024-08-09 16:00:45.310698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-08-09 16:00:45.314773: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2e336470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-09 16:00:45.314794: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti, Compute Capability 8.6\n",
      "2024-08-09 16:00:45.319236: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-09 16:00:45.400452: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3865/3865 [==============================] - 92s 21ms/step - loss: 0.0332 - accuracy: 0.9902 - precision: 0.9928 - recall: 0.9853 - binary_accuracy: 0.9902 - val_loss: 0.0301 - val_accuracy: 0.9927 - val_precision: 0.9995 - val_recall: 0.9842 - val_binary_accuracy: 0.9927\n",
      "Epoch 2/4\n",
      "3865/3865 [==============================] - 79s 20ms/step - loss: 0.0173 - accuracy: 0.9961 - precision: 0.9979 - recall: 0.9934 - binary_accuracy: 0.9961 - val_loss: 0.0265 - val_accuracy: 0.9944 - val_precision: 0.9975 - val_recall: 0.9900 - val_binary_accuracy: 0.9944\n",
      "Epoch 3/4\n",
      "3865/3865 [==============================] - 77s 20ms/step - loss: 0.0143 - accuracy: 0.9969 - precision: 0.9986 - recall: 0.9945 - binary_accuracy: 0.9969 - val_loss: 0.0273 - val_accuracy: 0.9952 - val_precision: 0.9997 - val_recall: 0.9897 - val_binary_accuracy: 0.9952\n",
      "Epoch 4/4\n",
      "3865/3865 [==============================] - 79s 20ms/step - loss: 0.0121 - accuracy: 0.9973 - precision: 0.9988 - recall: 0.9953 - binary_accuracy: 0.9973 - val_loss: 0.0297 - val_accuracy: 0.9953 - val_precision: 0.9999 - val_recall: 0.9898 - val_binary_accuracy: 0.9953\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator = augment_ecg_signal_batch(X_train, Y_train, batch_size)\n",
    "\n",
    "history = model.fit(train_generator, epochs=4, batch_size=batch_size, validation_data=(X_test, Y_test), steps_per_epoch=X_train.shape[0]//batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model-weights/Norm_RBBB_resnet_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 16:07:58.977973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:07:59.034863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:07:59.035065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:07:59.035453: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 16:07:59.036279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:07:59.036443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:07:59.036595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:07:59.489202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:07:59.489411: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:07:59.489571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-09 16:07:59.489706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5583 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "X_input = keras.Input(shape=X.shape[1:])\n",
    "_, feature_extractor = resnet.model(X_input, num_classes=1, filters = [16, 16], kernels = [5, 3], layers=10, hidden_units=128)\n",
    "feature_extractor_model = keras.Model(inputs=X_input, outputs=feature_extractor)\n",
    "\n",
    "# load weights from trained model\n",
    "feature_extractor_model.load_weights('model-weights/Norm_RBBB_resnet_classifier.h5', by_name=True)\n",
    "\n",
    "# save feature extractor model\n",
    "feature_extractor_model.save('model-weights/Norm_RBBB_resnet_feature_extractor.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
