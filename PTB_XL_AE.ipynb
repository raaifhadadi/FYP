{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 17:39:43.643312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-26 17:39:44.131131: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-26 17:39:44.131187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-26 17:39:44.131193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, metrics\n",
    "\n",
    "import data_visualisation as dv\n",
    "import data_augmentation as da\n",
    "import models.resnet as resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "thismodule = sys.modules[__name__]\n",
    "\n",
    "with np.load('data/PTB_XL_HB_1s_window.npz', allow_pickle=True) as data:\n",
    "    for k in data.keys():\n",
    "        if 'text' in k:\n",
    "            setattr(thismodule, k, data[k])\n",
    "        else:\n",
    "            setattr(thismodule, k, data[k].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an lstm autoencoder model\n",
    "# Define the LSTM-based autoencoder model\n",
    "class LSTMAutoencoder(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.encoder = layers.LSTM(latent_dim, activation='relu', return_sequences=False, input_shape=(100, 12))\n",
    "        self.repeat_vector = layers.RepeatVector(100)\n",
    "        self.decoder = layers.LSTM(12, activation='relu', return_sequences=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        repeated = self.repeat_vector(encoded)\n",
    "        decoded = self.decoder(repeated)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, latent_dim=64):\n",
    "    model = LSTMAutoencoder(latent_dim)\n",
    "    input = keras.Input(shape=input_shape)\n",
    "    output = model(input)\n",
    "    model = keras.Model(inputs=input, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(X_train.shape[1:], latent_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_ecg(ecg, mask_ratio=0.1):\n",
    "    block_size = 20\n",
    "    \n",
    "    for lead in range(ecg.shape[1]):\n",
    "        for i in range(0, ecg.shape[0], block_size):\n",
    "            if random.random() < mask_ratio:\n",
    "                ecg[i:i+block_size, lead] = 0\n",
    "    return ecg\n",
    "\n",
    "def mask_lead(ecg, mask_ratio=0.1):\n",
    "\n",
    "    for lead in range(ecg.shape[1]):\n",
    "        if random.random() < mask_ratio:\n",
    "            ecg[:, lead] = 0\n",
    "    return ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_ecg(ecg, mask_ratio=0.1, block_size=20):\n",
    "    ecg_shape = tf.shape(ecg)\n",
    "    num_blocks = ecg_shape[0] // block_size\n",
    "    \n",
    "    mask = tf.random.uniform([num_blocks, ecg_shape[1]], minval=0, maxval=1) < mask_ratio\n",
    "    mask = tf.reshape(tf.tile(mask[:, None, :], [1, block_size, 1]), ecg_shape)\n",
    "    \n",
    "    return tf.where(mask, tf.zeros_like(ecg), ecg)\n",
    "\n",
    "def mask_lead(ecg, mask_ratio=0.1):\n",
    "    ecg_shape = tf.shape(ecg)\n",
    "    \n",
    "    mask = tf.random.uniform([ecg_shape[1]], minval=0, maxval=1) < mask_ratio\n",
    "    mask = tf.tile(mask[None, :], [ecg_shape[0], 1])\n",
    "    \n",
    "    return tf.where(mask, tf.zeros_like(ecg), ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_ecg_signal(signal):\n",
    "    drifted_signal, _ = da.add_random_baseline_drift(signal, strength_range=(1.5,2.5), drift_wavelength_range=(300,500))\n",
    "    noised_drifted_signal = da.add_random_noise(drifted_signal, (0, 0.2))\n",
    "    res = mask_lead(noised_drifted_signal, mask_ratio=0.2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, data, epochs=50, batch_size=32):\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "    dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        steps = len(X_train) // batch_size\n",
    "        for step, batch in enumerate(dataset):\n",
    "            augmented_batch = tf.map_fn(augment_ecg_signal, batch)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                reconstructed = model(augmented_batch, training=True)\n",
    "                loss = loss_fn(batch, reconstructed)\n",
    "            \n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            \n",
    "            print(f\"\\rEpoch {epoch+1}/{epochs}, Step {step}/{steps}, Loss: {loss.numpy():.4f}\", end='')\n",
    "        model.save(f'model-weights/autoencoder_{epoch+1}.h5')\n",
    "        \n",
    "        # print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 17:41:27.412887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-05-26 17:41:27.835492: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x308be070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-26 17:41:27.835533: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti, Compute Capability 8.6\n",
      "2024-05-26 17:41:27.839364: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-26 17:41:27.915934: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x759b355f7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x759b355f7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/5, Step 7179/7179, Loss: 0.0412Epoch 2/5\n",
      "Epoch 2/5, Step 7179/7179, Loss: 0.0305Epoch 3/5\n",
      "Epoch 3/5, Step 7179/7179, Loss: 0.0386Epoch 4/5\n",
      "Epoch 4/5, Step 7179/7179, Loss: 0.0373Epoch 5/5\n",
      "Epoch 5/5, Step 7179/7179, Loss: 0.032844384"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train_autoencoder(model, X_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "modelk = keras.models.load_model('model-weights/autoencoder_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer encoder will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer decoder will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 12)]         0         \n",
      "                                                                 \n",
      " encoder (LSTM)              (None, 64)                19712     \n",
      "                                                                 \n",
      " repeat (RepeatVector)       (None, 100, 64)           0         \n",
      "                                                                 \n",
      " decoder (LSTM)              (None, 100, 12)           3696      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,408\n",
      "Trainable params: 23,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 17:41:15.894558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-26 17:41:15.961982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-26 17:41:15.962250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-26 17:41:15.963005: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-26 17:41:15.964043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-26 17:41:15.964286: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-26 17:41:15.964492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-26 17:41:16.438908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-26 17:41:16.439108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-26 17:41:16.439263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-26 17:41:16.439396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5640 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape, latent_dim=64):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.LSTM(64, activation='relu', return_sequences=False, name='encoder')(inputs)\n",
    "    x = layers.RepeatVector(100, name='repeat')(x)\n",
    "    x = layers.LSTM(12, activation='relu', return_sequences=True, name='decoder')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "model = make_model(X_train.shape[1:], latent_dim=128)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
